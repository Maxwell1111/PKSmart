# PKSmart CE50 Full Integration - Complete Guide

**Status:** All scripts created âœ… | Ready for execution â³
**Generated:** 2026-01-07

---

## ğŸ¯ Quick Start (5 Steps)

### Step 1: Install Dependencies
```bash
# Using conda (recommended)
conda install -c conda-forge rdkit mordred-descriptor
pip install scikit-learn pandas numpy matplotlib seaborn scipy

# OR using pip only
pip install rdkit mordred-descriptor scikit-learn pandas numpy matplotlib seaborn scipy
```

### Step 2: Train CE50-Enhanced Rat Models (~30-60 min)
```bash
python train_rat_models_with_ce50.py
```

### Step 3: Generate Enhanced Artificial Animal Data (~10-15 min)
```bash
python generate_artificial_animal_data_with_ce50.py
```

### Step 4: Train CE50-Enhanced Human Models (~60-90 min)
```bash
python train_human_models_with_ce50.py
```

### Step 5: Compare Results & Generate Visualizations (~5-10 min)
```bash
python compare_ce50_enhancement.py
```

**Total Time:** ~2-3 hours

---

## ğŸ“Š What Has Been Completed

### âœ… CE50 Predictions Generated

**Rat Dataset (324 compounds):**
- âœ… data/rat_ce50_predictions.csv
- âœ… data/rat_ce50_predictions_simple.csv
- âœ… rat_ce50_predictions_diagnostics.png

**Human Dataset (1,283 compounds):**
- âœ… data/human_ce50_predictions.csv
- âœ… data/human_ce50_predictions_simple.csv
- âœ… human_ce50_predictions_diagnostics.png

**Results:**
- Mean CE50: ~21.67 eV (both datasets)
- Success rate: 100%
- Confidence distribution: ~6% High, ~8% Medium, ~86% Low

### âœ… Training Scripts Created

1. **train_rat_models_with_ce50.py** (471 lines)
   - Trains 3 CE50-enhanced rat PK models
   - 542 features (539 baseline + 3 CE50)
   - Nested 5-fold CV with GridSearchCV

2. **generate_artificial_animal_data_with_ce50.py** (558 lines)
   - Uses CE50-enhanced rat models
   - Combines with baseline dog/monkey models
   - Generates 9 artificial predictions per compound

3. **train_human_models_with_ce50.py** (656 lines)
   - Trains 5 CE50-enhanced human PK models
   - 516 features (504 baseline + 3 CE50 + 9 enhanced animal)
   - Same robust training methodology

4. **compare_ce50_enhancement.py** (666 lines)
   - Comprehensive baseline vs CE50 comparison
   - Statistical testing (Wilcoxon signed-rank)
   - Feature importance analysis
   - 6 publication-quality visualizations

### âœ… Documentation Created

**Integration Guides:**
- CE50_INTEGRATION_GUIDE.md (main reference)
- CE50_INTEGRATION_STATUS.md (current status)
- README_FULL_INTEGRATION.md (this file)

**Training Documentation:**
- TRAIN_RAT_CE50_README.md
- TRAIN_HUMAN_CE50_README.md
- QUICKSTART_CE50_TRAINING.txt

**Comparison Documentation:**
- CE50_COMPARISON_README.md
- CE50_COMPARISON_QUICKSTART.md
- CE50_COMPARISON_SUMMARY.md
- example_ce50_output.txt

---

## ğŸ“ Complete File Structure

```
PKSmart/
â”‚
â”œâ”€â”€ ğŸ“Š DATA (âœ… COMPLETE)
â”‚   â”œâ”€â”€ data/rat_ce50_predictions.csv (324 compounds)
â”‚   â”œâ”€â”€ data/rat_ce50_predictions_simple.csv
â”‚   â”œâ”€â”€ data/human_ce50_predictions.csv (1,283 compounds)
â”‚   â””â”€â”€ data/human_ce50_predictions_simple.csv
â”‚
â”œâ”€â”€ ğŸ–¼ï¸ VISUALIZATIONS (âœ… COMPLETE)
â”‚   â”œâ”€â”€ rat_ce50_predictions_diagnostics.png
â”‚   â””â”€â”€ human_ce50_predictions_diagnostics.png
â”‚
â”œâ”€â”€ ğŸ”§ TRAINING SCRIPTS (âœ… CREATED, â³ NOT RUN)
â”‚   â”œâ”€â”€ train_rat_models_with_ce50.py
â”‚   â”œâ”€â”€ generate_artificial_animal_data_with_ce50.py
â”‚   â”œâ”€â”€ train_human_models_with_ce50.py
â”‚   â””â”€â”€ compare_ce50_enhancement.py
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS (âœ… CREATED)
â”‚   â”œâ”€â”€ 02a_Generate_CE50_for_rat_data.ipynb (âœ… executed)
â”‚   â”œâ”€â”€ 02_Predict_rat_data_with_CE50.ipynb
â”‚   â””â”€â”€ 03a_Generate_CE50_for_human_data.ipynb (âœ… executed)
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION (âœ… COMPLETE)
â”‚   â”œâ”€â”€ CE50_INTEGRATION_GUIDE.md
â”‚   â”œâ”€â”€ CE50_INTEGRATION_STATUS.md
â”‚   â”œâ”€â”€ README_FULL_INTEGRATION.md (this file)
â”‚   â”œâ”€â”€ TRAIN_RAT_CE50_README.md
â”‚   â”œâ”€â”€ TRAIN_HUMAN_CE50_README.md
â”‚   â”œâ”€â”€ QUICKSTART_CE50_TRAINING.txt
â”‚   â”œâ”€â”€ CE50_COMPARISON_README.md
â”‚   â”œâ”€â”€ CE50_COMPARISON_QUICKSTART.md
â”‚   â”œâ”€â”€ CE50_COMPARISON_SUMMARY.md
â”‚   â””â”€â”€ example_ce50_output.txt
â”‚
â””â”€â”€ ğŸ”¬ MODELS (â³ TO BE GENERATED)
    â”œâ”€â”€ Rat models (3 Ã— _ce50.sav)
    â”œâ”€â”€ Human models (5 Ã— _ce50.sav)
    â”œâ”€â”€ Scalers (8 Ã— .pkl)
    â”œâ”€â”€ Feature lists (2 Ã— .txt)
    â”œâ”€â”€ Results CSVs (4 files)
    â””â”€â”€ Comparison outputs (4 CSVs + 6 PNGs)
```

---

## ğŸ—ï¸ Architecture Overview

### Stage 1: Rat Model Enhancement (542 features)
```
INPUT: 324 rat compounds
  â†“
Morgan Fingerprints (153) + Mordred Descriptors (386) + CE50 Features (3)
  â†“
Train 3 Random Forest Models: VDss, CL, fup
  â†“
OUTPUT: 3 CE50-enhanced rat models
```

### Stage 2: Artificial Animal Data Generation
```
INPUT: 1,283 human compounds with CE50 predictions
  â†“
Predict with CE50-enhanced rat models (3 endpoints)
Predict with baseline dog models (3 endpoints)
Predict with baseline monkey models (3 endpoints)
  â†“
OUTPUT: 9 artificial animal predictions per compound
```

### Stage 3: Human Model Enhancement (516 features)
```
INPUT: 1,283 human compounds
  â†“
Morgan FP (152) + Mordred (352) + CE50 (3) + Enhanced Animal (9)
  â†“
Train 5 Random Forest Models: VDss, CL, fup, MRT, thalf
  â†“
OUTPUT: 5 CE50-enhanced human models
```

### Stage 4: Comprehensive Evaluation
```
INPUT: Baseline + CE50-enhanced results
  â†“
Calculate metrics: RÂ², RMSE, GMFE, Fold-2/3/5, Bias
Statistical testing: Wilcoxon signed-rank
Feature importance: Rank CE50 vs structural features
Confidence analysis: Stratify by High/Medium/Low
  â†“
OUTPUT: 4 CSVs + 6 visualizations + summary report
```

---

## ğŸ“ˆ Expected Improvements

### Conservative Estimates

**Rat Models (Stage 1):**
- RÂ² improvement: +5-10%
- GMFE reduction: -3-8%
- Fold-2 accuracy: +2-5 percentage points

**Human Models (Stage 3):**
- RÂ² improvement: +3-7% (compounded effect)
- GMFE reduction: -2-6%
- Fold-2 accuracy: +2-4 percentage points

### Success Criteria

**Minimum Requirements (to consider CE50 integration successful):**
1. âœ… At least 3/5 human endpoints show statistically significant improvement (p < 0.05)
2. âœ… No endpoint shows >5% performance degradation
3. âœ… CE50 features rank in top 50 features by importance for â‰¥3 endpoints

**Stretch Goals:**
1. ğŸ¯ All 5 human endpoints show improvement
2. ğŸ¯ >10% RÂ² improvement for at least 1 endpoint
3. ğŸ¯ High-confidence CE50 predictions show >2Ã— improvement vs low-confidence

---

## ğŸ”„ Detailed Execution Steps

### Prerequisites Check
```bash
# Check Python version (need 3.7+)
python --version

# Check if packages are installed
python -c "import rdkit; import mordred; import sklearn; print('âœ… All packages installed')"

# If above fails, run installation
conda install -c conda-forge rdkit mordred-descriptor
pip install scikit-learn pandas numpy matplotlib seaborn scipy
```

### Step 1: Train Rat Models

**Command:**
```bash
python train_rat_models_with_ce50.py > train_rat_log.txt 2>&1
```

**Expected Duration:** 30-60 minutes

**Progress Monitoring:**
```bash
# Watch progress in real-time
tail -f train_rat_log.txt

# Check if models are being generated
ls -lh log_rat_*_ce50_model*.sav
```

**Expected Outputs (8 files):**
```
log_rat_VDss_L_kg_model_ce50_FINAL.sav       (~500 KB)
log_rat_CL_mL_min_kg_model_ce50_FINAL.sav    (~500 KB)
log_rat_fup_model_ce50_FINAL.sav             (~500 KB)
scaler_rat_ce50.pkl                          (~10 KB)
features_mfp_mordred_ce50_columns_rat_model.txt (542 lines)
Prediction_rat_from_mordred_morgan_fs_ce50.csv (~50 KB)
rat_ce50.csv                                 (~1 KB)
+ Temporary model files during training
```

**Verify Success:**
```bash
# Check all required files exist
ls -lh log_rat_*_ce50_model_FINAL.sav scaler_rat_ce50.pkl features_mfp_mordred_ce50_columns_rat_model.txt

# Verify feature count
wc -l features_mfp_mordred_ce50_columns_rat_model.txt  # Should show 542

# Check performance summary
cat rat_ce50.csv
```

### Step 2: Generate Artificial Animal Data

**Command:**
```bash
python generate_artificial_animal_data_with_ce50.py > generate_animal_log.txt 2>&1
```

**Expected Duration:** 10-15 minutes

**Expected Outputs (3-4 files):**
```
Median_mordred_values_rat_for_artificial_animal_data_mfp_mrd_model_ce50.csv
Median_mordred_values_dog_for_artificial_animal_data_mfp_mrd_model.csv
Median_mordred_values_monkey_for_artificial_animal_data_mfp_mrd_model.csv
artificial_animal_data_with_ce50_TEMP.csv  (~500 KB)
```

**Verify Success:**
```bash
# Check all files exist
ls -lh Median_mordred_values_*_for_artificial_animal_data*.csv

# Verify artificial predictions file
wc -l artificial_animal_data_with_ce50_TEMP.csv  # Should be 1284 (1283 + header)

# Check column count (should have 9 artificial predictions + CE50 + human PK)
head -1 artificial_animal_data_with_ce50_TEMP.csv | tr ',' '\n' | wc -l
```

### Step 3: Train Human Models

**Command:**
```bash
python train_human_models_with_ce50.py > train_human_log.txt 2>&1 &

# Get process ID to monitor
echo $! > train_human.pid
```

**Expected Duration:** 60-90 minutes

**Monitor Progress:**
```bash
# Watch progress
tail -f train_human_log.txt

# Check if still running
ps -p $(cat train_human.pid)

# Check intermediate outputs
ls -lh log_human_*_ce50_model*.sav
```

**Expected Outputs (13 files):**
```
features_mfp_mordred_animal_ce50_columns_human.txt (516 lines)

log_human_VDss_L_kg_withanimaldata_artificial_ce50_model_FINAL.sav     (~1 MB)
log_human_CL_mL_min_kg_withanimaldata_artificial_ce50_model_FINAL.sav  (~1 MB)
log_human_fup_withanimaldata_artificial_ce50_model_FINAL.sav           (~1 MB)
log_human_mrt_withanimaldata_artificial_ce50_model_FINAL.sav           (~1 MB)
log_human_thalf_withanimaldata_artificial_ce50_model_FINAL.sav         (~1 MB)

artificial_animal_data_mfp_mrd_ce50_human_VDss_L_kg_scaler.pkl         (~20 KB)
artificial_animal_data_mfp_mrd_ce50_human_CL_mL_min_kg_scaler.pkl     (~20 KB)
artificial_animal_data_mfp_mrd_ce50_human_fup_scaler.pkl              (~20 KB)
artificial_animal_data_mfp_mrd_ce50_human_mrt_scaler.pkl              (~20 KB)
artificial_animal_data_mfp_mrd_ce50_human_thalf_scaler.pkl            (~20 KB)

Prediction_human_from_mordred_morgan_fs_animal_artificial_ce50.csv    (~200 KB)
human_with_mfp_mordred_animal_artificial_ce50.csv                     (~2 KB)
```

**Verify Success:**
```bash
# Check all model files
ls -lh log_human_*_ce50_model_FINAL.sav  # Should show 5 files

# Verify feature count
wc -l features_mfp_mordred_animal_ce50_columns_human.txt  # Should be 516

# Check performance summary
cat human_with_mfp_mordred_animal_artificial_ce50.csv
```

### Step 4: Compare Results

**Command:**
```bash
python compare_ce50_enhancement.py > comparison_report.txt 2>&1
```

**Expected Duration:** 5-10 minutes

**Expected Outputs (10 files):**
```
CSVs (4):
  ce50_comparison_report.csv          (comprehensive metrics)
  ce50_statistical_tests.csv          (p-values and significance)
  ce50_feature_importance.csv         (feature rankings)
  ce50_confidence_analysis.csv        (stratified by confidence)

Visualizations (6):
  performance_heatmap_ce50.png        (metric comparison heatmap)
  metric_comparison_ce50.png          (grouped bar charts)
  improvement_delta_ce50.png          (percentage improvements)
  feature_importance_ce50.png         (top 30 features highlighted)
  prediction_comparison_ce50.png      (scatter plots per endpoint)
  confidence_stratified_ce50.png      (performance by confidence level)
```

**Review Results:**
```bash
# View summary in terminal
cat comparison_report.txt

# Open visualizations
open *ce50*.png  # macOS
xdg-open *ce50*.png  # Linux

# Check comparison report
head -20 ce50_comparison_report.csv

# Check statistical significance
cat ce50_statistical_tests.csv

# Check feature importance
head -30 ce50_feature_importance.csv
```

---

## ğŸ” Interpreting Results

### Key Metrics to Check

**1. RÂ² (Coefficient of Determination)**
- Range: 0-1 (higher is better)
- Interpretation: Proportion of variance explained
- Target: Increase of +0.03 to +0.10

**2. RMSE (Root Mean Squared Error)**
- Range: 0-âˆ (lower is better)
- Interpretation: Average prediction error
- Target: Decrease of -0.05 to -0.15

**3. GMFE (Geometric Mean Fold Error)**
- Range: 1-âˆ (lower is better, 1 = perfect)
- Interpretation: Average fold-change error
- Target: Decrease from ~2.5 to ~2.2

**4. Fold-2 Accuracy**
- Range: 0-100% (higher is better)
- Interpretation: % of predictions within 2-fold of actual
- Target: Increase from ~55% to ~60-65%

**5. Statistical Significance**
- p-value < 0.05: Statistically significant improvement
- Target: At least 3/5 endpoints with p < 0.05

### Success Indicators

âœ… **Strong Success:**
- All 5 human endpoints show improvement
- 4+ endpoints with p < 0.05
- CE50 features in top 20 by importance
- High-confidence predictions show 2Ã— better improvement

âœ… **Moderate Success:**
- 3-4 human endpoints show improvement
- 3 endpoints with p < 0.05
- CE50 features in top 50 by importance
- Clear confidence gradient (High > Medium > Low)

âš ï¸ **Weak/Mixed Success:**
- 1-2 endpoints show improvement
- < 3 endpoints with p < 0.05
- CE50 features ranked low in importance
- No confidence gradient

âŒ **Failure:**
- No endpoints show improvement
- Any endpoint shows >5% degradation
- CE50 features have near-zero importance

---

## ğŸ› Troubleshooting

### Common Issues

**Issue 1: Missing Dependencies**
```bash
# Error: ModuleNotFoundError: No module named 'mordred'
# Solution:
conda install -c conda-forge mordred-descriptor rdkit
pip install scikit-learn pandas numpy
```

**Issue 2: Missing Baseline Models**
```bash
# Error: FileNotFoundError: log_dog_VDss_L_kg_model_FINAL.sav not found
# Solution: Train baseline models first or ensure they're in the correct directory
ls -lh log_*_model_FINAL.sav  # Check what models exist
```

**Issue 3: Memory Errors**
```bash
# Error: MemoryError or system slowdown
# Solution: Reduce n_jobs in GridSearchCV
# Edit script: Change n_jobs=30 to n_jobs=4 or n_jobs=2
```

**Issue 4: NaN Values in Mordred Descriptors**
```bash
# Warning: "Some Mordred descriptors returned NaN"
# This is normal for very small molecules
# The script handles this with median imputation
```

**Issue 5: Feature Count Mismatch**
```bash
# Error: "Expected 542 features, got 539"
# Solution: Verify CE50 predictions merged correctly
python -c "
import pandas as pd
df = pd.read_csv('data/rat_ce50_predictions_simple.csv')
print(f'CE50 predictions: {len(df)} compounds')
print(f'Columns: {df.columns.tolist()}')
"
```

---

## ğŸ“ Support & Documentation

### Documentation Files (in order of detail)

**Quick References:**
1. README_FULL_INTEGRATION.md (this file) - Complete guide
2. CE50_COMPARISON_QUICKSTART.md - Quick comparison guide
3. QUICKSTART_CE50_TRAINING.txt - Quick training guide

**Detailed References:**
4. CE50_INTEGRATION_GUIDE.md - Full integration reference
5. TRAIN_RAT_CE50_README.md - Rat model training details
6. TRAIN_HUMAN_CE50_README.md - Human model training details
7. CE50_COMPARISON_README.md - Comparison analysis details

**Status & Examples:**
8. CE50_INTEGRATION_STATUS.md - Current project status
9. example_ce50_output.txt - Sample outputs and interpretation

### Getting Help

**1. Check logs:**
```bash
tail -50 train_rat_log.txt      # Last 50 lines of rat training
tail -50 train_human_log.txt    # Last 50 lines of human training
tail -50 comparison_report.txt  # Comparison summary
```

**2. Verify file integrity:**
```bash
# Run test script
python test_ce50_comparison.py  # Validates all inputs

# Check file sizes
ls -lh *ce50*.{sav,pkl,csv,txt,png}
```

**3. Review documentation:**
- Start with QUICKSTART guides
- Refer to README files for details
- Check example_ce50_output.txt for expected results

---

## âœ… Final Checklist

Before starting:
- [ ] Python 3.7+ installed
- [ ] Dependencies installed (rdkit, mordred, sklearn, etc.)
- [ ] Baseline dog models available (if needed)
- [ ] Baseline monkey models available (if needed)
- [ ] CE50 predictions generated (rat + human)
- [ ] Sufficient disk space (~2 GB for all outputs)
- [ ] Sufficient RAM (â‰¥16 GB recommended)

After Step 1 (Rat models):
- [ ] 3 rat model files (.sav) exist
- [ ] scaler_rat_ce50.pkl exists
- [ ] Feature file has 542 lines
- [ ] Performance summary looks reasonable (GMFE ~2-3)

After Step 2 (Artificial data):
- [ ] 3 median values CSV files exist
- [ ] Artificial predictions file has 1283 compounds
- [ ] 9 artificial prediction columns present

After Step 3 (Human models):
- [ ] 5 human model files (.sav) exist
- [ ] 5 scaler files (.pkl) exist
- [ ] Feature file has 516 lines
- [ ] Performance summary looks reasonable

After Step 4 (Comparison):
- [ ] 4 comparison CSV files generated
- [ ] 6 visualization PNG files generated
- [ ] At least 3/5 endpoints show improvement
- [ ] CE50 features have meaningful importance

---

## ğŸ“ Scientific Validation

### Key Questions to Answer

1. **Does CE50 improve predictions?**
   - Check ce50_comparison_report.csv
   - Look for RÂ² increases and GMFE decreases

2. **Is the improvement statistically significant?**
   - Check ce50_statistical_tests.csv
   - Look for p-values < 0.05

3. **Which endpoints benefit most?**
   - Review improvement_delta_ce50.png
   - Identify endpoints with largest gains

4. **Are CE50 features important?**
   - Check ce50_feature_importance.csv
   - See where ce50/pce50/confidence rank

5. **Does confidence matter?**
   - Review confidence_stratified_ce50.png
   - Check if High confidence > Medium > Low

### Publication-Ready Outputs

All visualizations are generated at 300 DPI and suitable for publication:
- performance_heatmap_ce50.png - Main results figure
- metric_comparison_ce50.png - Detailed metrics
- feature_importance_ce50.png - Feature analysis
- confidence_stratified_ce50.png - Confidence validation

Tables in CSV format ready for supplementary materials:
- ce50_comparison_report.csv - Complete metrics table
- ce50_statistical_tests.csv - Statistical analysis
- ce50_feature_importance.csv - Feature rankings

---

## ğŸš€ Next Steps After Completion

### If CE50 Shows Strong Benefits:

1. **Integrate into production pipeline**
   - Use CE50-enhanced models for all new predictions
   - Update web interface to use new models
   - Document CE50 requirements for users

2. **Expand CE50 coverage**
   - Train CE50 models for more chemical space
   - Collect experimental CE50 data where possible
   - Improve confidence scoring system

3. **Publish results**
   - Write manuscript using generated visualizations
   - Include all metrics from comparison report
   - Discuss feature importance findings

### If CE50 Shows Mixed Results:

1. **Investigate which scenarios benefit**
   - Use confidence stratification insights
   - Identify chemical classes that benefit most
   - Consider selective CE50 application

2. **Refine approach**
   - Experiment with different CE50 transformations
   - Try different ways to incorporate confidence
   - Test other collision energy metrics

3. **Continue baseline as primary**
   - Keep CE50 as optional enhancement
   - Provide both predictions to users
   - Allow user selection based on compound

---

**END OF GUIDE**

For questions or issues, refer to the detailed documentation files or review the example outputs in `example_ce50_output.txt`.

**Last Updated:** 2026-01-07
**Version:** 1.0
**Status:** Ready for execution
