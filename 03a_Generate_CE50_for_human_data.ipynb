{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Generate CE50 Predictions for Human Dataset\n",
    "## Part of CE50 Integration into PKSmart\n",
    "\n",
    "This notebook generates CE50 predictions for all human compounds in the Human_PK_data.csv file.\n",
    "\n",
    "**Outputs:**\n",
    "- CE50 (collision energy in eV)\n",
    "- pCE50 = -log10(CE50)\n",
    "- Confidence score (0-6 scale from applicability domain)\n",
    "\n",
    "**Author:** Generated with Claude Code\n",
    "**Date:** 2026-01-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add CE50_prediction to path\n",
    "sys.path.append('./CE50_prediction')\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Human PK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load human PK data\n",
    "df_human = pd.read_csv('data/Human_PK_data.csv')\n",
    "\n",
    "print(f\"Total rows in Human_PK_data.csv: {len(df_human)}\")\n",
    "print(f\"\\nColumns: {df_human.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to get human compounds (any with human PK data)\n",
    "human_data = df_human[\n",
    "    df_human['human_VDss_L_kg'].notna() | \n",
    "    df_human['human_CL_mL_min_kg'].notna() | \n",
    "    df_human['human_fup'].notna() |\n",
    "    df_human['human_mrt'].notna() |\n",
    "    df_human['human_thalf'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of compounds with human PK data: {len(human_data)}\")\n",
    "print(f\"\\nHuman PK endpoints coverage:\")\n",
    "print(f\"  human_VDss_L_kg: {human_data['human_VDss_L_kg'].notna().sum()} compounds\")\n",
    "print(f\"  human_CL_mL_min_kg: {human_data['human_CL_mL_min_kg'].notna().sum()} compounds\")\n",
    "print(f\"  human_fup: {human_data['human_fup'].notna().sum()} compounds\")\n",
    "print(f\"  human_mrt: {human_data['human_mrt'].notna().sum()} compounds\")\n",
    "print(f\"  human_thalf: {human_data['human_thalf'].notna().sum()} compounds\")\n",
    "\n",
    "# Check SMILES column\n",
    "print(f\"\\nUnique SMILES: {human_data['smiles_r'].nunique()}\")\n",
    "print(f\"Missing SMILES: {human_data['smiles_r'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained CE50 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent model timestamp\n",
    "model_dir = 'CE50_prediction/models/'\n",
    "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')]\n",
    "\n",
    "# Extract timestamps from filenames\n",
    "timestamps = list(set([f.split('_')[-1].replace('.pkl', '') for f in model_files if 'metadata' not in f]))\n",
    "print(f\"Available model timestamps: {timestamps}\")\n",
    "\n",
    "# Use the most recent timestamp\n",
    "if len(timestamps) > 0:\n",
    "    timestamp = sorted(timestamps)[-1]  # Most recent\n",
    "    print(f\"\\nUsing models with timestamp: {timestamp}\")\n",
    "else:\n",
    "    raise ValueError(\"No CE50 models found in CE50_prediction/models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 4 ensemble models\n",
    "models = {}\n",
    "model_types = ['rf_binary', 'rf_count', 'xgb_binary', 'xgb_count']\n",
    "\n",
    "for model_type in model_types:\n",
    "    model_path = f\"{model_dir}{model_type}_{timestamp}.pkl\"\n",
    "    if os.path.exists(model_path):\n",
    "        models[model_type] = joblib.load(model_path)\n",
    "        print(f\"âœ“ Loaded {model_type}\")\n",
    "    else:\n",
    "        print(f\"âœ— Missing {model_type}\")\n",
    "\n",
    "# Load applicability domain\n",
    "ad_path = f\"{model_dir}applicability_domain_{timestamp}.pkl\"\n",
    "if os.path.exists(ad_path):\n",
    "    applicability_domain = joblib.load(ad_path)\n",
    "    print(f\"âœ“ Loaded applicability domain\")\n",
    "else:\n",
    "    applicability_domain = None\n",
    "    print(f\"âš  Applicability domain not found, confidence scores will be approximate\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Generate Dual Fingerprints for Human Compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_fingerprint(smiles, radius=2, n_bits=2048):\n",
    "    \"\"\"Generate binary Morgan fingerprint\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return np.array(fp)\n",
    "\n",
    "def generate_count_fingerprint(smiles, radius=2, n_bits=2048):\n",
    "    \"\"\"Generate count-based Morgan fingerprint\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=np.int32)\n",
    "    for idx, val in fp.GetNonzeroElements().items():\n",
    "        arr[idx] = val\n",
    "    return arr\n",
    "\n",
    "print(\"Fingerprint generation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fingerprints for all human compounds\n",
    "print(\"Generating fingerprints...\")\n",
    "\n",
    "binary_fps = []\n",
    "count_fps = []\n",
    "valid_indices = []\n",
    "invalid_smiles = []\n",
    "\n",
    "for idx, smiles in enumerate(human_data['smiles_r'].values):\n",
    "    if pd.isna(smiles):\n",
    "        invalid_smiles.append((idx, smiles, \"Missing SMILES\"))\n",
    "        continue\n",
    "    \n",
    "    binary_fp = generate_binary_fingerprint(smiles)\n",
    "    count_fp = generate_count_fingerprint(smiles)\n",
    "    \n",
    "    if binary_fp is not None and count_fp is not None:\n",
    "        binary_fps.append(binary_fp)\n",
    "        count_fps.append(count_fp)\n",
    "        valid_indices.append(idx)\n",
    "    else:\n",
    "        invalid_smiles.append((idx, smiles, \"Invalid SMILES\"))\n",
    "\n",
    "# Convert to arrays\n",
    "X_binary = np.array(binary_fps)\n",
    "X_count = np.array(count_fps)\n",
    "\n",
    "print(f\"\\nâœ“ Generated fingerprints for {len(valid_indices)} compounds\")\n",
    "print(f\"âœ— Failed for {len(invalid_smiles)} compounds\")\n",
    "print(f\"\\nFingerprint shapes:\")\n",
    "print(f\"  Binary: {X_binary.shape}\")\n",
    "print(f\"  Count: {X_count.shape}\")\n",
    "\n",
    "if len(invalid_smiles) > 0:\n",
    "    print(f\"\\nInvalid SMILES examples:\")\n",
    "    for idx, smiles, reason in invalid_smiles[:5]:\n",
    "        print(f\"  {reason}: {smiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Make CE50 Predictions with Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with all 4 models\n",
    "predictions = {}\n",
    "\n",
    "if 'rf_binary' in models:\n",
    "    predictions['rf_binary'] = models['rf_binary'].predict(X_binary)\n",
    "    print(f\"âœ“ RF Binary predictions: {len(predictions['rf_binary'])}\")\n",
    "\n",
    "if 'rf_count' in models:\n",
    "    predictions['rf_count'] = models['rf_count'].predict(X_count)\n",
    "    print(f\"âœ“ RF Count predictions: {len(predictions['rf_count'])}\")\n",
    "\n",
    "if 'xgb_binary' in models:\n",
    "    predictions['xgb_binary'] = models['xgb_binary'].predict(X_binary)\n",
    "    print(f\"âœ“ XGB Binary predictions: {len(predictions['xgb_binary'])}\")\n",
    "\n",
    "if 'xgb_count' in models:\n",
    "    predictions['xgb_count'] = models['xgb_count'].predict(X_count)\n",
    "    print(f\"âœ“ XGB Count predictions: {len(predictions['xgb_count'])}\")\n",
    "\n",
    "print(f\"\\nTotal models used: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble statistics\n",
    "all_preds = np.array(list(predictions.values())).T  # Shape: (n_compounds, n_models)\n",
    "\n",
    "# Mean prediction across ensemble\n",
    "pce50_ensemble_mean = all_preds.mean(axis=1)\n",
    "\n",
    "# Standard deviation (measure of ensemble disagreement)\n",
    "pce50_ensemble_std = all_preds.std(axis=1)\n",
    "\n",
    "# For each compound, select the model with highest confidence\n",
    "# (Simplified: use mean for now, can enhance with applicability domain later)\n",
    "pce50_predicted = pce50_ensemble_mean\n",
    "\n",
    "print(f\"Ensemble predictions generated:\")\n",
    "print(f\"  Mean pCE50: {pce50_predicted.mean():.3f} Â± {pce50_predicted.std():.3f}\")\n",
    "print(f\"  Range: [{pce50_predicted.min():.3f}, {pce50_predicted.max():.3f}]\")\n",
    "print(f\"  Ensemble disagreement (std): {pce50_ensemble_std.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Calculate Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence scores (simplified version)\n",
    "# Higher confidence when:\n",
    "# 1. Low ensemble disagreement (low std)\n",
    "# 2. Within applicability domain (if available)\n",
    "\n",
    "if applicability_domain is not None:\n",
    "    # Use applicability domain assessment\n",
    "    # This would require the full ApplicabilityDomain class\n",
    "    # For now, use simplified confidence based on ensemble agreement\n",
    "    print(\"Using applicability domain for confidence scores (TODO: implement)\")\n",
    "    confidence_scores = np.ones(len(pce50_predicted)) * 3  # Placeholder\n",
    "else:\n",
    "    # Simplified confidence: based on ensemble agreement\n",
    "    # Low std = high confidence\n",
    "    # Map std to 0-6 scale (inverted)\n",
    "    \n",
    "    # Normalize std to 0-1 range\n",
    "    std_normalized = (pce50_ensemble_std - pce50_ensemble_std.min()) / \\\n",
    "                     (pce50_ensemble_std.max() - pce50_ensemble_std.min() + 1e-10)\n",
    "    \n",
    "    # Convert to 0-6 scale (6 = highest confidence)\n",
    "    confidence_scores = 6 * (1 - std_normalized)\n",
    "    \n",
    "    print(f\"\\nConfidence scores (0-6 scale, based on ensemble agreement):\")\n",
    "    print(f\"  Mean: {confidence_scores.mean():.2f}\")\n",
    "    print(f\"  Range: [{confidence_scores.min():.2f}, {confidence_scores.max():.2f}]\")\n",
    "\n",
    "# Categorize confidence\n",
    "confidence_categories = np.where(confidence_scores >= 5, 'High',\n",
    "                        np.where(confidence_scores >= 3, 'Medium', 'Low'))\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "for cat in ['High', 'Medium', 'Low']:\n",
    "    count = (confidence_categories == cat).sum()\n",
    "    pct = 100 * count / len(confidence_categories)\n",
    "    print(f\"  {cat}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Convert pCE50 to CE50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pCE50 back to CE50 (eV)\n",
    "# pCE50 = -log10(CE50) â†’ CE50 = 10^(-pCE50)\n",
    "ce50_predicted = 10 ** (-pce50_predicted)\n",
    "\n",
    "print(f\"CE50 predictions (eV):\")\n",
    "print(f\"  Mean: {ce50_predicted.mean():.2f} eV\")\n",
    "print(f\"  Std: {ce50_predicted.std():.2f} eV\")\n",
    "print(f\"  Range: [{ce50_predicted.min():.2f}, {ce50_predicted.max():.2f}] eV\")\n",
    "print(f\"  Median: {np.median(ce50_predicted):.2f} eV\")\n",
    "\n",
    "# Expected range for small molecules: 10-50 eV typically\n",
    "in_expected_range = ((ce50_predicted >= 10) & (ce50_predicted <= 50)).sum()\n",
    "print(f\"\\n  Predictions in expected range (10-50 eV): {in_expected_range} / {len(ce50_predicted)} ({100*in_expected_range/len(ce50_predicted):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. Create Results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get valid human data (only compounds with successful predictions)\n",
    "human_data_valid = human_data.iloc[valid_indices].copy()\n",
    "\n",
    "# Add CE50 predictions\n",
    "human_data_valid['ce50'] = ce50_predicted\n",
    "human_data_valid['pce50'] = pce50_predicted\n",
    "human_data_valid['confidence'] = confidence_scores\n",
    "human_data_valid['confidence_category'] = confidence_categories\n",
    "human_data_valid['ensemble_std'] = pce50_ensemble_std\n",
    "\n",
    "# Add individual model predictions for transparency\n",
    "for model_name, preds in predictions.items():\n",
    "    human_data_valid[f'{model_name}_pce50'] = preds\n",
    "\n",
    "print(f\"Results DataFrame created with {len(human_data_valid)} compounds\")\n",
    "print(f\"\\nColumns added: ce50, pce50, confidence, confidence_category, ensemble_std, + individual model predictions\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "display_cols = ['smiles_r', 'ce50', 'pce50', 'confidence', 'confidence_category']\n",
    "if 'NAME' in human_data_valid.columns:\n",
    "    display_cols.insert(0, 'NAME')\n",
    "human_data_valid[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = 'data/human_ce50_predictions.csv'\n",
    "human_data_valid.to_csv(output_file, index=False)\n",
    "print(f\"âœ“ Saved results to: {output_file}\")\n",
    "print(f\"  Total rows: {len(human_data_valid)}\")\n",
    "print(f\"  Total columns: {len(human_data_valid.columns)}\")\n",
    "\n",
    "# Also save a simplified version with just essential columns\n",
    "essential_cols = ['smiles_r', 'human_VDss_L_kg', 'human_CL_mL_min_kg',\n",
    "                  'human_fup', 'human_mrt', 'human_thalf',\n",
    "                  'ce50', 'pce50', 'confidence', 'confidence_category', 'ensemble_std']\n",
    "\n",
    "# Only include NAME column if it exists\n",
    "if 'NAME' in human_data_valid.columns:\n",
    "    essential_cols.insert(1, 'NAME')\n",
    "\n",
    "human_ce50_simple = human_data_valid[essential_cols].copy()\n",
    "human_ce50_simple.to_csv('data/human_ce50_predictions_simple.csv', index=False)\n",
    "print(f\"\\nâœ“ Saved simplified version to: data/human_ce50_predictions_simple.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('CE50 Predictions for Human Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. CE50 distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(ce50_predicted, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(ce50_predicted.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {ce50_predicted.mean():.2f} eV')\n",
    "ax.axvline(np.median(ce50_predicted), color='orange', linestyle='--', linewidth=2, label=f'Median: {np.median(ce50_predicted):.2f} eV')\n",
    "ax.set_xlabel('CE50 (eV)', fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontweight='bold')\n",
    "ax.set_title('CE50 Distribution')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2. pCE50 distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(pce50_predicted, bins=30, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(pce50_predicted.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {pce50_predicted.mean():.3f}')\n",
    "ax.set_xlabel('pCE50 (-log10[CE50])', fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontweight='bold')\n",
    "ax.set_title('pCE50 Distribution')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Confidence score distribution\n",
    "ax = axes[0, 2]\n",
    "confidence_counts = pd.Series(confidence_categories).value_counts()\n",
    "colors = {'High': 'green', 'Medium': 'orange', 'Low': 'red'}\n",
    "bars = ax.bar(confidence_counts.index, confidence_counts.values, \n",
    "              color=[colors[x] for x in confidence_counts.index], edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Confidence Category', fontweight='bold')\n",
    "ax.set_ylabel('Number of Compounds', fontweight='bold')\n",
    "ax.set_title('Confidence Distribution')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}\\n({100*height/len(confidence_categories):.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Ensemble disagreement (std)\n",
    "ax = axes[1, 0]\n",
    "ax.hist(pce50_ensemble_std, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(pce50_ensemble_std.mean(), color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {pce50_ensemble_std.mean():.3f}')\n",
    "ax.set_xlabel('Ensemble Std (pCE50 units)', fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontweight='bold')\n",
    "ax.set_title('Ensemble Model Agreement')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 5. Model comparison (violin plot)\n",
    "ax = axes[1, 1]\n",
    "model_data = [predictions[m] for m in predictions.keys()]\n",
    "parts = ax.violinplot(model_data, positions=range(len(predictions)), \n",
    "                      showmeans=True, showmedians=True)\n",
    "ax.set_xticks(range(len(predictions)))\n",
    "ax.set_xticklabels(list(predictions.keys()), rotation=45, ha='right')\n",
    "ax.set_ylabel('pCE50 (-log10[CE50])', fontweight='bold')\n",
    "ax.set_title('Model Predictions Comparison')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Confidence vs Ensemble Std\n",
    "ax = axes[1, 2]\n",
    "scatter = ax.scatter(pce50_ensemble_std, confidence_scores, \n",
    "                    c=confidence_scores, cmap='RdYlGn', s=50, alpha=0.6, edgecolor='black')\n",
    "ax.set_xlabel('Ensemble Std (pCE50)', fontweight='bold')\n",
    "ax.set_ylabel('Confidence Score (0-6)', fontweight='bold')\n",
    "ax.set_title('Confidence vs Ensemble Agreement')\n",
    "plt.colorbar(scatter, ax=ax, label='Confidence')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('human_ce50_predictions_diagnostics.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nâœ“ Saved visualization: human_ce50_predictions_diagnostics.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CE50 PREDICTION SUMMARY FOR HUMAN DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ“Š DATASET STATISTICS:\")\n",
    "print(f\"  Total compounds in Human_PK_data.csv: {len(df_human)}\")\n",
    "print(f\"  Compounds with human PK data: {len(human_data)}\")\n",
    "print(f\"  Successful CE50 predictions: {len(human_data_valid)}\")\n",
    "print(f\"  Failed predictions: {len(invalid_smiles)}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ CE50 PREDICTIONS:\")\n",
    "print(f\"  Mean CE50: {ce50_predicted.mean():.2f} Â± {ce50_predicted.std():.2f} eV\")\n",
    "print(f\"  Median CE50: {np.median(ce50_predicted):.2f} eV\")\n",
    "print(f\"  Range: [{ce50_predicted.min():.2f}, {ce50_predicted.max():.2f}] eV\")\n",
    "print(f\"  25th percentile: {np.percentile(ce50_predicted, 25):.2f} eV\")\n",
    "print(f\"  75th percentile: {np.percentile(ce50_predicted, 75):.2f} eV\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ pCE50 PREDICTIONS:\")\n",
    "print(f\"  Mean pCE50: {pce50_predicted.mean():.3f} Â± {pce50_predicted.std():.3f}\")\n",
    "print(f\"  Range: [{pce50_predicted.min():.3f}, {pce50_predicted.max():.3f}]\")\n",
    "\n",
    "print(f\"\\nðŸŽ“ CONFIDENCE ASSESSMENT:\")\n",
    "for cat in ['High', 'Medium', 'Low']:\n",
    "    count = (confidence_categories == cat).sum()\n",
    "    pct = 100 * count / len(confidence_categories)\n",
    "    avg_conf = confidence_scores[confidence_categories == cat].mean()\n",
    "    print(f\"  {cat:8s}: {count:3d} compounds ({pct:5.1f}%) - Avg score: {avg_conf:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ¤– ENSEMBLE STATISTICS:\")\n",
    "print(f\"  Models used: {len(predictions)}\")\n",
    "print(f\"  Model types: {list(predictions.keys())}\")\n",
    "print(f\"  Ensemble disagreement (std): {pce50_ensemble_std.mean():.3f} Â± {pce50_ensemble_std.std():.3f}\")\n",
    "print(f\"  Max disagreement: {pce50_ensemble_std.max():.3f}\")\n",
    "print(f\"  Min disagreement: {pce50_ensemble_std.min():.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ OUTPUT FILES GENERATED:\")\n",
    "print(f\"  1. data/human_ce50_predictions.csv (full dataset)\")\n",
    "print(f\"  2. data/human_ce50_predictions_simple.csv (essential columns only)\")\n",
    "print(f\"  3. human_ce50_predictions_diagnostics.png (visualizations)\")\n",
    "\n",
    "print(f\"\\nâœ… CE50 prediction for human dataset COMPLETE!\")\n",
    "print(f\"\\nNext step: Create 03_Predict_human_data_with_CE50.ipynb to retrain human models with these CE50 features\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
